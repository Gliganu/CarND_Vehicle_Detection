{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "from skimage.feature import hog\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "from sklearn.svm import LinearSVC\n",
    "import time\n",
    "from moviepy.editor import *\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_paths(folder_path):\n",
    "    subfolders = glob(folder_path + \"*\")\n",
    "    img_paths = []\n",
    "    \n",
    "    for subfolder in tqdm(subfolders):\n",
    "        subfolder_img_paths = glob(subfolder+\"/*\")\n",
    "    \n",
    "        for path in subfolder_img_paths:\n",
    "            img_paths.append(path)\n",
    "            \n",
    "    return img_paths\n",
    "\n",
    "def show_imgs(data_df,label_value,nr_images):\n",
    "    for _,row in data_df[data_df['label_str'] == label_value].iloc[:nr_images].iterrows():\n",
    "        img = row['img']\n",
    "        plt.figure(figsize=(5,5))\n",
    "        \n",
    "        plt.imshow(img)\n",
    "    \n",
    "        plt.show()\n",
    "        \n",
    "def read_image(path):\n",
    "    img = PIL.Image.open(path)\n",
    "    img = np.asarray(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def create_dataframe(vehicle_paths, non_vehicle_paths):\n",
    "    vehicle_df = pd.DataFrame({\n",
    "        \"img_path\": vehicle_paths,\n",
    "        \"img\": [read_image(path) for path in tqdm(vehicle_paths)],\n",
    "        \"label\":1,\n",
    "        \"label_str\":\"vehicle\"\n",
    "    })\n",
    "    \n",
    "    non_vehicle_df = pd.DataFrame({\n",
    "        \"img_path\": non_vehicle_paths,\n",
    "        \"img\": [read_image(path) for path in tqdm(non_vehicle_paths)],\n",
    "        \"label\":0,\n",
    "        \"label_str\":\"non_vehicle\"\n",
    "    })\n",
    "    \n",
    "    data_df = pd.concat([vehicle_df,non_vehicle_df])\n",
    "    data_df = data_df.set_index(\"img_path\")\n",
    "    data_df = shuffle(data_df,random_state = 0)\n",
    "    \n",
    "    return data_df     \n",
    "\n",
    "\n",
    "def split_train_test(data_df, train_percentage):\n",
    "    \n",
    "    nr_train = int(train_percentage * len(data_df))\n",
    "    train_df = data_df[:nr_train]\n",
    "    test_df = data_df[nr_train:]\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "def scale_column(data_df, column_name):\n",
    "    col_values = np.stack(data_df[column_name].tolist())\n",
    "    scaler = StandardScaler().fit(col_values)\n",
    "\n",
    "    scaled_col_values = scaler.transform(col_values)\n",
    "    \n",
    "    data_df.loc[:,column_name] = pd.Series([v for v in scaled_col_values], index = data_df.index)\n",
    "    \n",
    "    return data_df, scaler\n",
    "\n",
    "def get_features_and_labels_from_df(df):\n",
    "    X = np.stack(df['features'].tolist())\n",
    "    y = np.stack(df['label'].tolist())\n",
    "    \n",
    "    return (X,y)\n",
    "\n",
    "def save_obj(model,path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "        \n",
    "def load_obj(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        entry = pickle.load(f) \n",
    "    return entry    \n",
    "\n",
    "def augment_data(data_df):\n",
    "    augm_df = data_df.copy()\n",
    "    augm_df.loc[:,\"img\"] = augm_df.loc[:,\"img\"].progress_apply(lambda img: cv2.flip(img,1))\n",
    "\n",
    "    return shuffle(pd.concat([data_df,augm_df]),random_state=0)\n",
    "\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "\n",
    "    features = hog(img, orientations=orient, \n",
    "                   pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                   cells_per_block=(cell_per_block, cell_per_block), \n",
    "                   transform_sqrt=True, \n",
    "                   visualise=vis, feature_vector=feature_vec)\n",
    "    return features\n",
    "\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to compute color histogram features \n",
    "# NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "def single_img_features(img):    \n",
    "\n",
    "    img_features = []\n",
    "    feature_image = np.copy(img)      \n",
    "    \n",
    "    if SPATIAL_FEAT == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=SPATIAL_SIZE)\n",
    "        img_features.append(spatial_features)\n",
    "        \n",
    "    if HIST_FEAT == True:\n",
    "        hist_features = color_hist(feature_image, nbins=HIST_BINS)\n",
    "        img_features.append(hist_features)\n",
    "        \n",
    "    if HOG_FEAT == True:\n",
    "        if HOG_CHANNEL == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                    ORIENT, PIX_PER_CELL, CELL_PER_BLOCK, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], ORIENT, \n",
    "                        PIX_PER_CELL, CELL_PER_BLOCK, vis=False, feature_vec=True)\n",
    "        img_features.append(hog_features)\n",
    "\n",
    "    return np.concatenate(img_features)\n",
    "\n",
    "def add_features(data_df):\n",
    "    data_df.loc[:,\"features\"] = data_df.loc[:,\"img\"].progress_apply(lambda img: single_img_features(img))\n",
    "    return data_df\n",
    "\n",
    "def add_features_multiproc(data_df):\n",
    "    data_df_array = np.array_split(data_df,16)\n",
    "    \n",
    "    threads_number = multiprocessing.cpu_count() // 2\n",
    "    pool = Pool(threads_number)\n",
    "    data_df_with_hog_array = pool.map(add_features, data_df_array)\n",
    "    pool.close()\n",
    "    \n",
    "    return pd.concat(data_df_with_hog_array)\n",
    "\n",
    "\n",
    "def add_heat(heatmap, bbox_list):\n",
    "\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    return heatmap\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    \n",
    "    return heatmap\n",
    "\n",
    "def draw_boxes(img, bboxes, title):\n",
    "\n",
    "    imcopy = np.copy(img)\n",
    "    for bbox in bboxes:\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], (0, 0, 255), 6)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.imshow(imcopy)\n",
    "    plt.show()\n",
    "\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    \n",
    "    ctrans_tosearch = img[ystart:ystop,:,:]\n",
    "\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = np.asarray(PIL.Image.fromarray(ctrans_tosearch).resize((np.int(imshape[1]/scale), np.int(imshape[0]/scale))))\n",
    "    \n",
    "    ctrans_tosearch = cv2.cvtColor(ctrans_tosearch, cv2.COLOR_RGB2YCrCb)\n",
    "    \n",
    "#     plt.imshow(ctrans_tosearch)\n",
    "#     plt.figure()\n",
    "#     plt.show()\n",
    "    \n",
    "#     ctrans_tosearch = ctrans_tosearch.astype(np.float32)/255\n",
    "    \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "\n",
    "    cells_per_step = 1# Instead of overlap, define how many cells to step\n",
    "    \n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    \n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    cars_bboxes = []\n",
    "    \n",
    "    for xb in tqdm(range(nxsteps)):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            \n",
    "#             for rect_scale in [1,1.3]:\n",
    "              for rect_scale in [1]:\n",
    "\n",
    "    #             subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "                subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+int(window*rect_scale)], (64,64))\n",
    "\n",
    "\n",
    "                spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "                hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "\n",
    "                raw_test_features = np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1)\n",
    "                test_features = X_scaler.transform(raw_test_features)    \n",
    "\n",
    "                test_prediction = svc.predict(test_features)\n",
    "\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "\n",
    "            \n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6)                             \n",
    "            \n",
    "#                 new_img = np.copy(img)\n",
    "#                 cv2.rectangle(new_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6)                             \n",
    "#                 plt.title(\"Scale = {}\\nRect = {}\".format(scale,rect_scale))\n",
    "#                 plt.imshow(new_img)\n",
    "#                 plt.figure()\n",
    "#                 plt.show()\n",
    "\n",
    "                if test_prediction == 1:\n",
    "                    xbox_left = np.int(xleft*scale)\n",
    "                    ytop_draw = np.int(ytop*scale)\n",
    "                    win_draw = np.int(window*scale)\n",
    "\n",
    "    #                 cars_bboxes.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "                    cars_bboxes.append(((xbox_left, ytop_draw+ystart),(xbox_left+int(win_draw*rect_scale),ytop_draw+win_draw+ystart)))\n",
    "\n",
    "#                     new_img = np.copy(img)\n",
    "#                     cv2.rectangle(new_img,(xbox_left, ytop_draw+ystart),(xbox_left+int(win_draw*rect_scale),ytop_draw+win_draw+ystart),(0,0,255),6)                             \n",
    "#                     plt.title(\"Scale = {}\\nRect = {}\".format(scale,rect_scale))\n",
    "#                     plt.imshow(new_img)\n",
    "#                     plt.figure()\n",
    "#                     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#     plt.title(\"Scale = {}\\nRect = {}\".format(scale,rect_scale))\n",
    "#     plt.imshow(draw_img)\n",
    "#     plt.figure()\n",
    "#     plt.show()\n",
    "\n",
    "    return cars_bboxes\n",
    "    \n",
    "def get_merged_windows(img, hot_windows, heatmap_threshold):\n",
    "     \n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float32)\n",
    "    heat = add_heat(heat,hot_windows)\n",
    "    heat = apply_threshold(heat,heatmap_threshold)\n",
    "    heat = np.clip(heat, 0, 255)\n",
    "    labels = label(heat)\n",
    "    \n",
    "    bboxes = []\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        bboxes.append(bbox)\n",
    "        \n",
    "    return bboxes, heat\n",
    "\n",
    "def get_car_bboxes(data):\n",
    "    \n",
    "    img, scales = data\n",
    "        \n",
    "    ystart = img.shape[0] // 2\n",
    "    ystop = int(img.shape[0] * 0.9)\n",
    "\n",
    "    all_car_windows = []\n",
    "    \n",
    "    for scale in scales:\n",
    "        scale_cars_windows = find_cars(img, ystart, ystop, scale, svc, X_scaler, ORIENT, PIX_PER_CELL, CELL_PER_BLOCK, SPATIAL_SIZE, HIST_BINS)\n",
    "        \n",
    "        all_car_windows += scale_cars_windows\n",
    "\n",
    "    return img, all_car_windows\n",
    "\n",
    "\n",
    "def get_car_bboxes_multiproc(imgs,scales):\n",
    "\n",
    "    pool = Pool(30)\n",
    "    \n",
    "    scales_arr = [scales] * len(imgs)\n",
    "        \n",
    "    t = time.time()\n",
    "    results_arr = pool.map(get_car_bboxes, zip(imgs,scales_arr))\n",
    "    pool.close()\n",
    "    t2 = time.time()\n",
    "    print(\"Time = {}\".format(round(t2-t, 2)))\n",
    "    \n",
    "    return results_arr\n",
    "                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vehicle_paths = read_paths(\"../../datasets/udacity/vehicle_detection/vehicles/\")\n",
    "non_vehicle_paths = read_paths(\"../../datasets/udacity/vehicle_detection/non-vehicles/\")\n",
    "\n",
    "data_df = create_dataframe(vehicle_paths, non_vehicle_paths)\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_imgs(data_df,\"vehicle\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_imgs(data_df,\"non_vehicle\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df = augment_data(data_df)\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Tweak these parameters and see how the results change.\n",
    "ORIENT = 9  # HOG orientations\n",
    "PIX_PER_CELL = 8 # HOG pixels per cell\n",
    "CELL_PER_BLOCK = 2 # HOG cells per block\n",
    "HOG_CHANNEL = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "SPATIAL_SIZE = (16, 16) # Spatial binning dimensions\n",
    "HIST_BINS = 16    # Number of histogram bins\n",
    "\n",
    "SPATIAL_FEAT = True # Spatial features on or off\n",
    "HIST_FEAT = True # Histogram features on or off\n",
    "HOG_FEAT = True # HOG features on or off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df = add_features_multiproc(data_df)\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_train_test(data_df, train_percentage = 0.8)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = get_features_and_labels_from_df(train_df)\n",
    "test_X, test_y = get_features_and_labels_from_df(test_df)\n",
    "\n",
    "X_scaler = StandardScaler().fit(train_X)\n",
    "train_X = X_scaler.transform(train_X)\n",
    "test_X = X_scaler.transform(test_X)\n",
    "\n",
    "print(\"Train {} and {}\".format(train_X.shape,train_y.shape))\n",
    "print(\"Test {} and {}\".format(test_X.shape,test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = LinearSVC(C=1.0, loss='hinge', max_iter=1000, random_state=0, verbose=1)\n",
    "svc = LinearSVC(C=0.1, loss='hinge', max_iter=1000, random_state=0, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Old Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = load_obj(\"./svc.pickle\")\n",
    "# X_scaler = load_obj(\"./X_scaler.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t=time.time()\n",
    "svc.fit(train_X, train_y)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = round(svc.score(train_X, train_y), 4)\n",
    "test_accuracy = round(svc.score(test_X, test_y), 4)\n",
    "\n",
    "print('Train Accuracy of SVC = ', train_accuracy)\n",
    "print('Test Accuracy of SVC = ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(svc,\"./svc.pickle\")\n",
    "save_obj(X_scaler,\"./X_scaler.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viz Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = svc.predict(test_X)\n",
    "test_df.loc[:,'pred']  = pd.Series(test_predictions, index=test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (_, row) in enumerate(test_df.iterrows()):\n",
    "    if(row[\"pred\"] == 1 and row[\"label\"] == 1 and idx < 100):\n",
    "        plt.imshow(row[\"img\"])\n",
    "        plt.figure()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_img_size = (768,480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = sorted(glob(\"./test_images/*\"))\n",
    "imgs = [np.asarray(PIL.Image.open(img_path).resize(default_img_size)) for img_path in img_paths]\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scales = [0.7,1,1.5]\n",
    "results_arr = get_car_bboxes_multiproc(imgs,scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img, all_car_windows in results_arr:\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    ht_list = [2,3,5,7,10,15,20,50,100]\n",
    "    for i, ht in enumerate(ht_list):\n",
    "        \n",
    "        merged_bboxes, heatmap = get_merged_windows(img, all_car_windows, heatmap_threshold = ht)   \n",
    "        \n",
    "        draw_img = np.copy(img)\n",
    "        \n",
    "        if len(merged_bboxes) != 0:\n",
    "            for bbox in merged_bboxes:\n",
    "                cv2.rectangle(draw_img,bbox[0],bbox[1],(0,0,255),6) \n",
    "                \n",
    "        plt.subplot(1,len(ht_list),i+1)\n",
    "        plt.title(ht)\n",
    "        plt.imshow(draw_img)\n",
    "        \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,(img, all_car_windows) in enumerate(results_arr):\n",
    "\n",
    "    merged_bboxes, heatmap = get_merged_windows(img, all_car_windows, heatmap_threshold = 10)   \n",
    "\n",
    "    draw_img = np.copy(img)\n",
    "\n",
    "    if len(merged_bboxes) != 0:\n",
    "        for bbox in merged_bboxes:\n",
    "            cv2.rectangle(draw_img,bbox[0],bbox[1],(0,0,255),6) \n",
    "\n",
    "    PIL.Image.fromarray(draw_img).save(\"./output_images/result_img_\"+str(i)+\".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scales = [0.7,0.8,1,1.25,1.5]\n",
    "\n",
    "for img_path in tqdm(sorted(glob(\"./test_images/*\"))):\n",
    "        \n",
    "    img = np.asarray(PIL.Image.open(img_path).resize(default_img_size)) \n",
    "    \n",
    "    _, all_car_windows = get_car_bboxes((img, scales))\n",
    "    \n",
    "    merged_bboxes, heatmap = get_merged_windows(img, all_car_windows, heatmap_threshold = 0)   \n",
    "\n",
    "    if len(merged_bboxes) != 0:\n",
    "        for bbox in merged_bboxes:\n",
    "            cv2.rectangle(img,bbox[0],bbox[1],(0,0,255),6) \n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(heatmap)\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clip1 = VideoFileClip(\"./project_video.mp4\")\n",
    "frames = np.stack([np.asarray(PIL.Image.fromarray(frame).resize(default_img_size)) for frame in tqdm(list(clip1.iter_frames()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_slices = frames#[1::25]\n",
    "frames_slices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for f in frames_slices[:10]:\n",
    "#     plt.imshow(f)\n",
    "#     plt.figure()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scales = [0.7,0.8,0.9,1,1.1,1.2,1.5,1.7]\n",
    "scales = [0.7,1,1.5]\n",
    "results_arr = get_car_bboxes_multiproc(frames_slices,scales)\n",
    "\n",
    "with open('results_arr.pickle', 'wb') as handle:\n",
    "    pickle.dump(results_arr, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img, all_car_windows in results_arr:\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    ht_list = [2,3,5,7,10,15,20,50,100]\n",
    "    \n",
    "    for i, ht in enumerate(ht_list):\n",
    "        \n",
    "        merged_bboxes, heatmap = get_merged_windows(img, all_car_windows, heatmap_threshold = ht)   \n",
    "        \n",
    "        draw_img = np.copy(img)\n",
    "        \n",
    "        if len(merged_bboxes) != 0:\n",
    "            for bbox in merged_bboxes:\n",
    "                cv2.rectangle(draw_img,bbox[0],bbox[1],(0,0,255),6) \n",
    "                \n",
    "        plt.subplot(1,len(ht_list),i+1)\n",
    "        plt.title(ht)\n",
    "        plt.imshow(draw_img)\n",
    "            \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clips = []\n",
    "\n",
    "# for img, all_car_windows in results_arr:\n",
    "\n",
    "#     merged_bboxes, heatmap = get_merged_windows(img, all_car_windows, heatmap_threshold = 1)   \n",
    "#     draw_img = np.copy(img)\n",
    "        \n",
    "#     if len(merged_bboxes) != 0:\n",
    "#         for bbox in merged_bboxes:\n",
    "#             cv2.rectangle(draw_img,bbox[0],bbox[1],(0,0,255),6) \n",
    "\n",
    "#     clips.append(ImageClip(draw_img).set_duration(4))\n",
    "    \n",
    "# out_clip = concatenate_videoclips(clips)\n",
    "# out_clip.write_videofile(\"./test.mp4\", fps=3)\n",
    "\n",
    "# HTML(\"\"\"\n",
    "# <video width=\"768\" height=\"480\" controls>\n",
    "#   <source src=\"{0}\">\n",
    "# </video>\n",
    "# \"\"\".format(\"./test.mp4\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create results dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_img_mean_to_bbox_dict(results_arr):\n",
    "    nr_frames_to_include = 5\n",
    "\n",
    "    img_mean_to_bbox = {}\n",
    "    for index in tqdm(range(nr_frames_to_include,len(results_arr))):\n",
    "        frame_results_arr = results_arr[index - nr_frames_to_include:index]\n",
    "\n",
    "        img, _ = frame_results_arr[-1]\n",
    "\n",
    "        all_frame_car_windows = []\n",
    "        for _, all_car_windows in frame_results_arr:\n",
    "            all_frame_car_windows += all_car_windows\n",
    "\n",
    "            ht = 30\n",
    "\n",
    "        merged_bboxes, heatmap = get_merged_windows(img, all_frame_car_windows, heatmap_threshold = ht)   \n",
    "\n",
    "        draw_img = np.copy(img)\n",
    "\n",
    "        if len(merged_bboxes) != 0:\n",
    "            for bbox in merged_bboxes:\n",
    "                cv2.rectangle(draw_img,bbox[0],bbox[1],(0,0,255),6) \n",
    "\n",
    "        img_mean_to_bbox[np.average(img)] = draw_img\n",
    "        \n",
    "    return img_mean_to_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mean_to_bbox = create_img_mean_to_bbox_dict(results_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    img = np.asarray(PIL.Image.fromarray(img).resize(default_img_size)) \n",
    "    img_avg = np.average(img) \n",
    "    \n",
    "    if img_avg in img_mean_to_bbox:\n",
    "        return img_mean_to_bbox[img_avg]\n",
    "        \n",
    "    return img\n",
    "\n",
    "# def process_image(img):\n",
    "#     img = np.asarray(PIL.Image.fromarray(img).resize(default_img_size)) \n",
    "#     img_avg = np.average(img) \n",
    "    \n",
    "#     if img_avg in img_mean_to_bbox:\n",
    "#         img = img_mean_to_bbox[img_avg]\n",
    "        \n",
    "#     return np.asarray(PIL.Image.fromarray(img).resize((384,240)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clip1 = VideoFileClip(\"./project_video.mp4\")\n",
    "video_output = './project_video_output.mp4'\n",
    "white_clip = clip1.fl_image(process_image)\n",
    "white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results_arr.pickle', 'rb') as handle:\n",
    "    results_arr = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nr_frames_to_include = 5\n",
    "# delta_to_plot = 20\n",
    "\n",
    "# for index in range(nr_frames_to_include,len(results_arr)):\n",
    "#     frame_results_arr = results_arr[index - nr_frames_to_include:index]\n",
    "    \n",
    "#     img, _ = frame_results_arr[-1]\n",
    "    \n",
    "#     all_frame_car_windows = []\n",
    "#     for _, all_car_windows in frame_results_arr:\n",
    "#         all_frame_car_windows += all_car_windows\n",
    "        \n",
    "#     if index%delta_to_plot == 0:\n",
    "#         plt.figure(figsize=(20,20))\n",
    "    \n",
    "#     ht_list = [5,10,15,20,25]\n",
    "# #     ht_list = [5]\n",
    "#     for i, ht in enumerate(ht_list):\n",
    "        \n",
    "#         merged_bboxes, heatmap = get_merged_windows(img, all_frame_car_windows, heatmap_threshold = ht)   \n",
    "        \n",
    "#         draw_img = np.copy(img)\n",
    "        \n",
    "#         if len(merged_bboxes) != 0:\n",
    "#             for bbox in merged_bboxes:\n",
    "#                 cv2.rectangle(draw_img,bbox[0],bbox[1],(0,0,255),6) \n",
    "\n",
    "#         if index%delta_to_plot == 0:\n",
    "#             plt.subplot(1,len(ht_list),i+1)\n",
    "#             plt.title(ht)\n",
    "#             plt.imshow(draw_img)\n",
    "            \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nr_frames_to_include = 5\n",
    "delta_to_plot = 20\n",
    "\n",
    "for index in range(nr_frames_to_include,len(results_arr),100):\n",
    "    frame_results_arr = results_arr[index - nr_frames_to_include:index]\n",
    "    \n",
    "    img, _ = frame_results_arr[-1]\n",
    "    \n",
    "    all_frame_car_windows = []\n",
    "    for _, all_car_windows in frame_results_arr:\n",
    "        all_frame_car_windows += all_car_windows\n",
    "        \n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    merged_bboxes, heatmap = get_merged_windows(img, all_frame_car_windows, heatmap_threshold = 30)   \n",
    "\n",
    "    draw_img = np.copy(img)\n",
    "\n",
    "    if len(merged_bboxes) != 0:\n",
    "        for bbox in merged_bboxes:\n",
    "            cv2.rectangle(draw_img,bbox[0],bbox[1],(0,0,255),6) \n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(draw_img)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(heatmap)\n",
    "               \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
